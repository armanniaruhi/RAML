{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries",
   "id": "79996820810450ee"
  },
  {
   "cell_type": "code",
   "id": "f0d2de51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T21:37:03.555021Z",
     "start_time": "2025-05-27T21:36:56.814105Z"
    }
   },
   "source": [
    "from src.preprocessing.dataLoader_CelebA import get_partitioned_dataloaders, create_subset_loader\n",
    "from src.ml.resNet50 import SiameseResNet\n",
    "import torch\n",
    "from src.ml.hyperparam_study import run_optuna_study"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import losses",
   "id": "de5d4a137ee7011e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T21:37:03.772484Z",
     "start_time": "2025-05-27T21:37:03.742181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_metric_learning.losses import ContrastiveLoss\n",
    "from pytorch_metric_learning.losses import MarginLoss\n",
    "from pytorch_metric_learning.losses import AngularLoss\n",
    "from pytorch_metric_learning.losses import CosFaceLoss\n",
    "from pytorch_metric_learning.losses import MultiSimilarityLoss\n",
    "from pytorch_metric_learning.losses import HistogramLoss"
   ],
   "id": "ac91d47fd7b66b6b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "bd34605c",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "id": "b95e4ac4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T21:37:03.811461Z",
     "start_time": "2025-05-27T21:37:03.805821Z"
    }
   },
   "source": [
    "IMAGE_DIR = \"data/celeba/img_align_celeba\"\n",
    "LABEL_FILE = \"data/celeba/identity_CelebA.txt\"\n",
    "PARTITION_FILE = \"data/celeba/list_eval_partition.csv\"\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "2a41272680289e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T21:37:06.915552Z",
     "start_time": "2025-05-27T21:37:03.875379Z"
    }
   },
   "source": [
    "train_loader, val_loader, test_loader = get_partitioned_dataloaders(image_dir= IMAGE_DIR,\n",
    "                                                               label_file= LABEL_FILE,\n",
    "                                                               partition_file= PARTITION_FILE,\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               img_size=IMG_SIZE)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "edf17a00",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "a5ce9a92a3b04d2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T21:37:07.636076Z",
     "start_time": "2025-05-27T21:37:06.935826Z"
    }
   },
   "source": [
    "model = SiameseResNet()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "a64873c2d6b338a",
   "metadata": {},
   "source": [
    "# Find best Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eff55d",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T21:37:07.672059Z",
     "start_time": "2025-05-27T21:37:07.666961Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-5, weight_decay=1e-4)",
   "id": "f73a3707486bef90",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T21:37:07.741533Z",
     "start_time": "2025-05-27T21:37:07.732087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contrastive_loss = ContrastiveLoss(neg_margin=1.0, pos_margin=0)\n",
    "histogram_loss = HistogramLoss(n_bins=1000)\n",
    "multi_similarity_loss = MultiSimilarityLoss()\n",
    "margin_loss = MarginLoss(margin=0.5)"
   ],
   "id": "e986cef3a8d96a76",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-27T21:37:07.801316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = model.train_model(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=histogram_loss,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=10,\n",
    "        device=DEVICE,\n",
    "        patience=5,\n",
    "        experiment_name='SiameseResNet',\n",
    "        tuning_mode=False\n",
    "    )"
   ],
   "id": "dbb3faca84ebca6b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 34/5086 [03:39<9:04:11,  6.46s/it, batch_loss=0.24866499]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 1001 is out of bounds for dimension 0 with size 1001",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m results = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m        \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhistogram_loss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpatience\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexperiment_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mSiameseResNet\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtuning_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/RAML1/src/ml/resNet50.py:159\u001B[39m, in \u001B[36mSiameseResNet.train_model\u001B[39m\u001B[34m(self, train_loader, val_loader, criterion, num_epochs, optimizer, device, experiment_name, tuning_mode, patience)\u001B[39m\n\u001B[32m    157\u001B[39m optimizer.zero_grad()\n\u001B[32m    158\u001B[39m embeddings = \u001B[38;5;28mself\u001B[39m(imgs)\n\u001B[32m--> \u001B[39m\u001B[32m159\u001B[39m loss = \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    160\u001B[39m loss.backward()\n\u001B[32m    161\u001B[39m optimizer.step()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.conda/envs/RAML/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.conda/envs/RAML/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.conda/envs/RAML/lib/python3.13/site-packages/pytorch_metric_learning/losses/base_metric_loss_function.py:34\u001B[39m, in \u001B[36mBaseMetricLossFunction.forward\u001B[39m\u001B[34m(self, embeddings, labels, indices_tuple, ref_emb, ref_labels)\u001B[39m\n\u001B[32m     32\u001B[39m     labels = c_f.to_device(labels, embeddings)\n\u001B[32m     33\u001B[39m ref_emb, ref_labels = c_f.set_ref_emb(embeddings, labels, ref_emb, ref_labels)\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m loss_dict = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[43m    \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices_tuple\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mref_emb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mref_labels\u001B[49m\n\u001B[32m     36\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[38;5;28mself\u001B[39m.add_embedding_regularization_to_loss_dict(loss_dict, embeddings)\n\u001B[32m     38\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.reducer(loss_dict, embeddings, labels)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.conda/envs/RAML/lib/python3.13/site-packages/pytorch_metric_learning/losses/histogram_loss.py:46\u001B[39m, in \u001B[36mHistogramLoss.compute_loss\u001B[39m\u001B[34m(self, embeddings, labels, indices_tuple, ref_emb, ref_labels)\u001B[39m\n\u001B[32m     43\u001B[39m ap_dists = mat[anchor_positive_idx]\n\u001B[32m     44\u001B[39m an_dists = mat[anchor_negative_idx]\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m p_pos = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_density\u001B[49m\u001B[43m(\u001B[49m\u001B[43map_dists\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     47\u001B[39m phi = torch.cumsum(p_pos, dim=\u001B[32m0\u001B[39m)\n\u001B[32m     49\u001B[39m p_neg = \u001B[38;5;28mself\u001B[39m.compute_density(an_dists)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.conda/envs/RAML/lib/python3.13/site-packages/pytorch_metric_learning/losses/histogram_loss.py:74\u001B[39m, in \u001B[36mHistogramLoss.compute_density\u001B[39m\u001B[34m(self, distances)\u001B[39m\n\u001B[32m     71\u001B[39m density = c_f.to_device(density, tensor=distances, dtype=distances.dtype)\n\u001B[32m     73\u001B[39m \u001B[38;5;66;03m# For each node sum the contributions of the bins whose ending node is this one\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m74\u001B[39m \u001B[43mdensity\u001B[49m\u001B[43m.\u001B[49m\u001B[43mscatter_add_\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mr_star\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelta_ijr_a\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m \u001B[38;5;66;03m# For each node sum the contributions of the bins whose starting node is this one\u001B[39;00m\n\u001B[32m     76\u001B[39m density.scatter_add_(\u001B[32m0\u001B[39m, r_star, delta_ijr_b)\n",
      "\u001B[31mRuntimeError\u001B[39m: index 1001 is out of bounds for dimension 0 with size 1001"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_loader_study = (create_subset_loader(train_loader,10000))\n",
    "val_loader_study = (create_subset_loader(train_loader,2000))\n",
    "study = run_optuna_study(train_loader_study, val_loader_study, n_trials=10, study_name=\"siamese_constrastive_HP_study\")\n",
    "best_params = study.best_params"
   ],
   "id": "1222fa4ca3cc18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot the results",
   "id": "6c88db09120a25bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "! mlflow ui --port 5000",
   "id": "35184fd98283adb4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
